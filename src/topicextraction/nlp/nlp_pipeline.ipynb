{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "# Topic extraction from the GEPRiS dataset and creation of an user-centric visualisation\n",
    "Author: Tim Korjakow        \n",
    "Summer term 2018      \n",
    "Freie Universität Berlin     \n",
    "Fachgebiet Human-Centered Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "![Process graph](nlpflowchart.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%load_ext Cython\n",
    "#initialize profiler\n",
    "#%load_ext line_profiler\n",
    "\n",
    "import time\n",
    "import json\n",
    "import spacy\n",
    "import regex as re\n",
    "from langdetect import detect\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF as NonnegativeMatrixFactorization\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "from MulticoreTSNE import MulticoreTSNE\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from lapjv import lapjv\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.interpolate import griddata\n",
    "from numpy.linalg import norm\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Javascript, HTML\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import ColumnDataSource, OpenURL, TapTool\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.palettes import d3\n",
    "from bokeh.layouts import row, column\n",
    "output_notebook()\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True) # for offline mode use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "## Loading and Cleaning\n",
    "The first step in every NLP project which works with texts is always the preparation of the input data. In this example the Project dump from GEPRIS is loaded and the project descriptions are extracted. After that the texts get cleaned by removing all non-alphabetic chars and all stopwords from the texts. English texts are getting filtered in oder to make the analysis simpler and more comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "outputs": [],
   "source": [
    "def loadProjects():\n",
    "    with open('../../../assets/data/project_output/projects.json', 'r') as datafile:\n",
    "        return json.load(datafile)\n",
    "\n",
    "def loadGermanStopwords():\n",
    "    with open('../../../assets/data/nlp/stopwords_de.json', 'r') as datafile:\n",
    "        return json.load(datafile)\n",
    "\n",
    "def loadEnglishStopwords():\n",
    "    with open('../../../assets/data/nlp/stopwords_eng.json', 'r') as datafile:\n",
    "        return json.load(datafile)\n",
    "\n",
    "def cleanProjectTexts():\n",
    "    cleanedProjectTexts = {}\n",
    "    stopwordsDE = set(loadGermanStopwords())\n",
    "    for project in loadProjects():\n",
    "        if project['abstract'] and project['abstract'] != 'Keine Zusammenfassung vorhanden' and detect(project['abstract']) == 'de':\n",
    "            if len(cleanedProjectTexts) >= 400:\n",
    "                break\n",
    "            letters_only = re.sub('[^\\p{L} ]', ' ', project['abstract'])\n",
    "            words = letters_only.lower().split()\n",
    "            usefulWords = [x for x in words if not (x in stopwordsDE or len(x) <= 2 )]\n",
    "            if usefulWords:\n",
    "                cleanedProjectTexts[project['id']] = ' '.join(usefulWords)\n",
    "    return cleanedProjectTexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "## TF-IDF computation\n",
    "*Summary*:\n",
    "This technique vectorizes a corpus, e.g. a collection of documents, by counting all appearences of words in the corpus and computing the tf-idf measure for each document, word pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('de')\n",
    "def lemmatize(text):\n",
    "    return [token.lemma_ for token in nlp(text)]\n",
    "\n",
    "def TfIdf(dict):\n",
    "    start = time.time()\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer=lemmatize)\n",
    "    tfs = tfidf_vectorizer.fit_transform(list(dict.values()))\n",
    "    print('TFIDF execution time: ', time.time() - start)\n",
    "    return (tfidf_vectorizer, tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF execution time:  2.4072327613830566\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer, tfs = TfIdf(cleanProjectTexts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "# Topic extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "## Latent Semantic Analysis\n",
    "*Summary*:\n",
    "The LSA transforms an corpus from its word space given by the tf-idf matrice into its semantic space. In this semantic space the dimensions denote topics in the corpus and every document vector is a linear combination of all the implicitly extracted topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSA(tfs,num_topics=40):\n",
    "    start = time.time()\n",
    "    lsa = TruncatedSVD(n_components=num_topics, random_state=0).fit(tfs)\n",
    "    print('LSA execution time: ', time.time() - start)\n",
    "    \n",
    "    #tfidf_feature_names = [str(token) for token in tfidf_vectorizer.get_feature_names()]\n",
    "    #print_top_words(lsa, tfidf_feature_names, 10)\n",
    "    return lsa.transform(tfs), lsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "## Non-negative matrix factorisation\n",
    "Summary: **Coming soon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMF(tfs,num_topics=40):\n",
    "    start = time.time()\n",
    "    nmf = NonnegativeMatrixFactorization(n_components=num_topics, init='random', random_state=0)\n",
    "    nmf.fit(tfs)    \n",
    "    print('NMF execution time: ', time.time() - start)\n",
    "    \n",
    "    #\n",
    "    #print_top_words(nmf, tfidf_feature_names, 10)\n",
    "    return nmf.transform(tfs), nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "### Get top words for each dimension\n",
    "In order to get the words which are most important for each dimension (which correspond to topics), the standard basis in the topic space is converted back into the word space. These are exactly the eigenvectors of data. Now the top n biggest entries and their corresponding words form the top words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words_dim(model, feature_names, n_top_words):\n",
    "    dim_topics = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        dim_topics[topic_idx] = [feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "    return dim_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "## K-Means\n",
    "Summary: Given a clustering the LDA can be used to find a projection into a lower dimensional space which maximizes inter-class variance and minimizes intra-class variance. This leads to neater cluster, but is grounded in the hypotheses that the clusters have some real semantic meaning. Otherwise it may enforce preexisting biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterNumberHeuristic(tfs):\n",
    "    return (tfs.shape[0]*tfs.shape[1])//tfs.count_nonzero()\n",
    "\n",
    "def cluster(tfs_reduced, num_topics=10):\n",
    "    start = time.time()\n",
    "    km = KMeans(n_clusters=num_topics).fit(tfs_reduced)\n",
    "    print('Clustering execution time: ', time.time() - start)\n",
    "    return km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "### Get top words for each cluster\n",
    "The process is similar to the one for getting the top words for each dimension. But in this case the cluster centers from the clustering step are transformed back into the word space and analysed. This is based on the assumption that the cluster center represents the set of all documents in the corrsponding cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words_cluster(model, clustering_centers, feature_names, n_top_words):\n",
    "    cluster_topics = {}\n",
    "    word_space_cluster_centers = model.inverse_transform(clustering_centers)\n",
    "    for i, word_space_cluster in enumerate(word_space_cluster_centers):\n",
    "        cluster_topics[i] = [feature_names[j]\n",
    "                        for j in word_space_cluster.argsort()[:-n_top_words - 1:-1]]\n",
    "    return cluster_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "# Embedding into 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "## Linear Discriminant Analysis\n",
    "*Summary*:\n",
    "Given a clustering the LDA can be used to find a projection into a lower dimensional space which maximizes inter-class variance and minimizes intra-class variance. This leads to neater cluster, but is grounded in the hypotheses that the clusters have some real semantic meaning. Otherwise it may enforce preexisting biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimReductionLDA(tfs_reduced, clusters, targetDim=2):\n",
    "    start = time.time()\n",
    "    lda = LinearDiscriminantAnalysis(n_components=targetDim)\n",
    "    tfs_2d = lda.fit(tfs_reduced, clusters.labels_).transform(tfs_reduced)\n",
    "    print('LDA execution time: ', time.time() - start)\n",
    "    print(lda.coef_.shape, lda.xbar_.shape)\n",
    "    return tfs_2d, lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "## tSNE\n",
    "*Summary*:\n",
    "\n",
    "\n",
    "*In-depth explanation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimReductiontSNE(tfs_reduced, perplexity=30, learning_rate=100, targetDim=2):\n",
    "    start = time.time()\n",
    "    tfs_2d = (MulticoreTSNE(n_jobs=8, n_components=targetDim, perplexity=perplexity, learning_rate=learning_rate) if targetDim ==2 else TSNE(n_components=targetDim, perplexity=perplexity, learning_rate=learning_rate)).fit_transform(tfs_reduced)\n",
    "    print('tSNE execution time: ', time.time() - start)\n",
    "    return tfs_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abadeh': matrix([[11.20321334]]), 'abb': matrix([[12.2347437]]), 'abbilden': matrix([[9.3035669]]), 'abbilder': matrix([[9.72048619]]), 'abbildungen': matrix([[9.52158385]]), 'abcd': matrix([[10.42453198]]), 'abfolge': matrix([[10.08656951]]), 'abfolgen': matrix([[9.73631655]]), 'abgebildet': matrix([[10.99715232]]), 'abgeflacht': matrix([[9.1175745]]), 'abgelegen': matrix([[9.01124996]]), 'abgeleitet': matrix([[10.54957948]]), 'abgereicherten': matrix([[7.58630212]]), 'abgeschlossen': matrix([[10.00721198]]), 'abgewandelt': matrix([[8.06657112]]), 'abgrenzen': matrix([[8.24247645]]), 'abholzungen': matrix([[11.43698508]]), 'abhängig': matrix([[10.14603588]]), 'abhängigkeit': matrix([[10.0284306]]), 'abhängigkeiten': matrix([[9.16147812]]), 'abiotischen': matrix([[9.53922337]]), 'abiotischer': matrix([[10.47284688]]), 'abkühlgeschichte': matrix([[11.05955552]]), 'ablagerung': matrix([[7.90616018]]), 'ablagerungen': matrix([[6.58064593]]), 'ablagerungsgeschichte': matrix([[8.18855894]]), 'ablauf': matrix([[7.40932492]]), 'ablaufen': matrix([[7.53394323]]), 'ablaufend': matrix([[6.46880752]]), 'ableiten': matrix([[7.52262296]]), 'ableitung': matrix([[8.83909711]]), 'abmessungen': matrix([[7.92859528]]), 'abrufen': matrix([[7.45470338]]), 'abschirmen': matrix([[7.51435976]]), 'abschließen': matrix([[9.09478257]]), 'abschließend': matrix([[8.89468352]]), 'abschluss': matrix([[10.49794923]]), 'abschmelzung': matrix([[6.82827505]]), 'abschnitte': matrix([[8.74365464]]), 'abschätzen': matrix([[6.4395376]]), 'abschätzung': matrix([[7.80165755]]), 'abschätzungen': matrix([[8.06596877]]), 'absicherung': matrix([[7.70503589]]), 'absinken': matrix([[6.40145488]]), 'absolut': matrix([[7.50897985]]), 'abstammen': matrix([[7.85550509]]), 'abständen': matrix([[7.26857814]]), 'abtragen': matrix([[7.71392799]]), 'abundanz': matrix([[9.3690561]]), 'abwandern': matrix([[7.45132651]]), 'abwanderungsverhalten': matrix([[6.5082239]]), 'abwandlungen': matrix([[9.79381027]]), 'abwechslungsreich': matrix([[7.9133142]]), 'acanthochitona': matrix([[7.53438955]]), 'acanthodier': matrix([[6.77316449]]), 'access': matrix([[10.36691956]]), 'acentropinae': matrix([[8.35549015]]), 'achondrite': matrix([[9.27993822]]), 'aculeata': matrix([[6.24687931]]), 'aculeate': matrix([[8.66745126]]), 'aculeaten': matrix([[5.73039335]]), 'aculeater': matrix([[7.31239539]]), 'aculifera': matrix([[5.98792658]]), 'adaptation': matrix([[8.6652508]]), 'adaptive': matrix([[10.19774819]]), 'adaptiven': matrix([[6.43960235]]), 'addax': matrix([[7.15612964]]), 'adelphotaxon': matrix([[8.50536543]]), 'aderung': matrix([[11.59098324]]), 'adressieren': matrix([[8.27768867]]), 'adulten': matrix([[10.63185975]]), 'adäquat': matrix([[8.6929828]]), 'aerobe': matrix([[9.1882406]]), 'aflp': matrix([[7.85350493]]), 'afm': matrix([[7.96989924]]), 'afrika': matrix([[11.10991408]]), 'afrikanisch': matrix([[7.5723167]]), 'afrikas': matrix([[8.64923566]]), 'afrotropis': matrix([[8.42595775]]), 'akkretion': matrix([[7.96255712]]), 'akkretioniert': matrix([[8.65332833]]), 'akkretionierten': matrix([[9.66411451]]), 'akkretioniertes': matrix([[11.10135159]]), 'akkretionsgeschichte': matrix([[7.83632996]]), 'akkretionsphase': matrix([[7.19395918]]), 'akkretionsrate': matrix([[8.1045485]]), 'akkumulationsquote': matrix([[11.5693873]]), 'akkumulationsrate': matrix([[11.37663912]]), 'aktiv': matrix([[9.12014386]]), 'aktive': matrix([[10.33524276]]), 'aktivität': matrix([[7.06489724]]), 'aktualisieren': matrix([[7.65215133]]), 'aktualisierung': matrix([[7.93500832]]), 'aktuell': matrix([[8.47412877]]), 'akustisch': matrix([[9.37054671]]), 'akustische': matrix([[6.42113692]]), 'akzeptieren': matrix([[5.62211229]]), 'akzessorischer': matrix([[10.18552492]]), 'algorithmen': matrix([[5.62072233]]), 'alkenon': matrix([[9.2732756]]), 'alkenongehalte': matrix([[9.07097509]]), 'all': matrix([[9.65824504]])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"bf3eb6bf-c76a-4bfe-b9d4-a8c803fe5f62\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"65ee59b3-d33c-4ab6-b7b4-376389c9cd23\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1012\",\"type\":\"CategoricalAxis\"}],\"left\":[{\"id\":\"1016\",\"type\":\"LinearAxis\"}],\"plot_height\":800,\"plot_width\":800,\"renderers\":[{\"id\":\"1012\",\"type\":\"CategoricalAxis\"},{\"id\":\"1015\",\"type\":\"Grid\"},{\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"id\":\"1020\",\"type\":\"Grid\"},{\"id\":\"1029\",\"type\":\"BoxAnnotation\"},{\"id\":\"1039\",\"type\":\"GlyphRenderer\"}],\"title\":null,\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1004\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"1008\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"1006\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1010\",\"type\":\"LinearScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"data_source\":{\"id\":\"1036\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1037\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1038\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"1040\",\"type\":\"CDSView\"}},\"id\":\"1039\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1047\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1013\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1013\",\"type\":\"CategoricalTicker\"}},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1021\",\"type\":\"PanTool\"},{\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"id\":\"1024\",\"type\":\"SaveTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"HelpTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"overlay\":{\"id\":\"1029\",\"type\":\"BoxAnnotation\"}},\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1006\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null,\"data\":{\"top\":[{\"__ndarray__\":\"dN4ulAtoJkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"XsKZUzB4KEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"wZ/5Hm2bIkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"uLPNkONwI0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"pFa1CQ0LI0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"I31nQVzZJEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"JPCs1lIsJEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"M6W8e/54I0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"8gCkv4r+JUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"+em0uTI8IkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"eFsrjsIFIkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"qNk8e2IZJUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"3iH/lF9YHkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"jnbjSbEDJEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"o3MOnBUiIEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"oyNo3yV8IEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"kjIegrzfJkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"Ou0ZN8VKJEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"TFKGdI4OJEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"hYi0Qq1SIkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"PVjrFRUUI0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"NoyP/BjyJEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"daelD34eJkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"100DdOifH0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"7zSk2JRSGkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"0QdMzIpgIEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"RFuEEiajHUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"LldGA8IiHkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"5DX6Ew/gGUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"etRWeSoXHkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"sUrSIp6tIUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"XpSIruG2H0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"qoQVw53RHUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"GYBCU7QOHkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"R7ZxV4cwIkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"XeR69RPKIUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"x6KlM/P+JEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"4oroVSdQG0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"kHEQTcB8IUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"cCk/JRbCGUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"Q4E9t+U0H0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"RZmTqMYhIEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"krNX7fTRHkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"WzgJ/RabGUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"Ok+8AzIJHkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"IKwNhwlsH0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"r3UbJgYTHUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"68uG8A/bHkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"O4fJ6/S8IkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"PbhKiSjOHUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"gXfL2GsIGkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"YC2bTG6WI0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"5UCM1junH0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"c41lAzcjHkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"iFPSbrgXG0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"TT5v4dy7JEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"NrD9zQK2IEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"kZ0AEFSPIkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"qJJb7s38GEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"sx7yK7xVIUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"LWI8POzrFkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"UZfzk+Q/HUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"+XGwBqPzF0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"0yfcwJtUIUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"55geQD9lJEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"uvYLHifCGUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"zwrQcuCfHEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"b/rSQb8CIUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"SI77WpUuJ0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"kkKKNS2OIEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"m2zxHoNDJUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"PRospM5iIUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"FtRDEmFgIkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"KV87Mv1pH0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"VmIwRC3hH0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"6peVqEY4JkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"3QzTYw1KHkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"XHisnWhMIUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"m0lOIhfaIEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"MDKVkqjZH0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"QNH4DIFOIUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"cgYN0QZUI0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"p/MNW+QzJkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"g1I/4WZYH0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"93pFPJ3GHEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"PA+IYYc1IEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"2NRdu4YjJ0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"LdK519bAJkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"leYWf4M9IkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"JTKE8KSrJEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"mmk9bHRCHEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"20Ifj82bHkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"PXsV0nK9H0A=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"BGmJAcHyIEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"pDBbTLi9IkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"Tkd2hD6vGUA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"9aLsAAt9FkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"07xMH/1eJEA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"ykqHop57FkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"hUCCx+qLIkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"Z0nG2FYkIkA=\",\"dtype\":\"float64\",\"shape\":[1,1]},{\"__ndarray__\":\"w855fgVRI0A=\",\"dtype\":\"float64\",\"shape\":[1,1]}],\"x\":[\"abadeh\",\"abb\",\"abbilden\",\"abbilder\",\"abbildungen\",\"abcd\",\"abfolge\",\"abfolgen\",\"abgebildet\",\"abgeflacht\",\"abgelegen\",\"abgeleitet\",\"abgereicherten\",\"abgeschlossen\",\"abgewandelt\",\"abgrenzen\",\"abholzungen\",\"abh\\u00e4ngig\",\"abh\\u00e4ngigkeit\",\"abh\\u00e4ngigkeiten\",\"abiotischen\",\"abiotischer\",\"abk\\u00fchlgeschichte\",\"ablagerung\",\"ablagerungen\",\"ablagerungsgeschichte\",\"ablauf\",\"ablaufen\",\"ablaufend\",\"ableiten\",\"ableitung\",\"abmessungen\",\"abrufen\",\"abschirmen\",\"abschlie\\u00dfen\",\"abschlie\\u00dfend\",\"abschluss\",\"abschmelzung\",\"abschnitte\",\"absch\\u00e4tzen\",\"absch\\u00e4tzung\",\"absch\\u00e4tzungen\",\"absicherung\",\"absinken\",\"absolut\",\"abstammen\",\"abst\\u00e4nden\",\"abtragen\",\"abundanz\",\"abwandern\",\"abwanderungsverhalten\",\"abwandlungen\",\"abwechslungsreich\",\"acanthochitona\",\"acanthodier\",\"access\",\"acentropinae\",\"achondrite\",\"aculeata\",\"aculeate\",\"aculeaten\",\"aculeater\",\"aculifera\",\"adaptation\",\"adaptive\",\"adaptiven\",\"addax\",\"adelphotaxon\",\"aderung\",\"adressieren\",\"adulten\",\"ad\\u00e4quat\",\"aerobe\",\"aflp\",\"afm\",\"afrika\",\"afrikanisch\",\"afrikas\",\"afrotropis\",\"akkretion\",\"akkretioniert\",\"akkretionierten\",\"akkretioniertes\",\"akkretionsgeschichte\",\"akkretionsphase\",\"akkretionsrate\",\"akkumulationsquote\",\"akkumulationsrate\",\"aktiv\",\"aktive\",\"aktivit\\u00e4t\",\"aktualisieren\",\"aktualisierung\",\"aktuell\",\"akustisch\",\"akustische\",\"akzeptieren\",\"akzessorischer\",\"algorithmen\",\"alkenon\",\"alkenongehalte\",\"all\"]},\"selected\":{\"id\":\"1046\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1047\",\"type\":\"UnionRenderers\"}},\"id\":\"1036\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{\"formatter\":{\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1008\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":10},\"x\":{\"field\":\"x\"}},\"id\":\"1038\",\"type\":\"VBar\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"top\"},\"width\":{\"value\":10},\"x\":{\"field\":\"x\"}},\"id\":\"1037\",\"type\":\"VBar\"},{\"attributes\":{\"formatter\":{\"id\":\"1043\",\"type\":\"CategoricalTickFormatter\"},\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1013\",\"type\":\"CategoricalTicker\"}},\"id\":\"1012\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"callback\":null,\"factors\":[\"abadeh\",\"abb\",\"abbilden\",\"abbilder\",\"abbildungen\",\"abcd\",\"abfolge\",\"abfolgen\",\"abgebildet\",\"abgeflacht\",\"abgelegen\",\"abgeleitet\",\"abgereicherten\",\"abgeschlossen\",\"abgewandelt\",\"abgrenzen\",\"abholzungen\",\"abh\\u00e4ngig\",\"abh\\u00e4ngigkeit\",\"abh\\u00e4ngigkeiten\",\"abiotischen\",\"abiotischer\",\"abk\\u00fchlgeschichte\",\"ablagerung\",\"ablagerungen\",\"ablagerungsgeschichte\",\"ablauf\",\"ablaufen\",\"ablaufend\",\"ableiten\",\"ableitung\",\"abmessungen\",\"abrufen\",\"abschirmen\",\"abschlie\\u00dfen\",\"abschlie\\u00dfend\",\"abschluss\",\"abschmelzung\",\"abschnitte\",\"absch\\u00e4tzen\",\"absch\\u00e4tzung\",\"absch\\u00e4tzungen\",\"absicherung\",\"absinken\",\"absolut\",\"abstammen\",\"abst\\u00e4nden\",\"abtragen\",\"abundanz\",\"abwandern\",\"abwanderungsverhalten\",\"abwandlungen\",\"abwechslungsreich\",\"acanthochitona\",\"acanthodier\",\"access\",\"acentropinae\",\"achondrite\",\"aculeata\",\"aculeate\",\"aculeaten\",\"aculeater\",\"aculifera\",\"adaptation\",\"adaptive\",\"adaptiven\",\"addax\",\"adelphotaxon\",\"aderung\",\"adressieren\",\"adulten\",\"ad\\u00e4quat\",\"aerobe\",\"aflp\",\"afm\",\"afrika\",\"afrikanisch\",\"afrikas\",\"afrotropis\",\"akkretion\",\"akkretioniert\",\"akkretionierten\",\"akkretioniertes\",\"akkretionsgeschichte\",\"akkretionsphase\",\"akkretionsrate\",\"akkumulationsquote\",\"akkumulationsrate\",\"aktiv\",\"aktive\",\"aktivit\\u00e4t\",\"aktualisieren\",\"aktualisierung\",\"aktuell\",\"akustisch\",\"akustische\",\"akzeptieren\",\"akzessorischer\",\"algorithmen\",\"alkenon\",\"alkenongehalte\",\"all\"]},\"id\":\"1004\",\"type\":\"FactorRange\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1029\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"source\":{\"id\":\"1036\",\"type\":\"ColumnDataSource\"}},\"id\":\"1040\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTickFormatter\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.4\"}};\n",
       "  var render_items = [{\"docid\":\"65ee59b3-d33c-4ab6-b7b4-376389c9cd23\",\"roots\":{\"1002\":\"bf3eb6bf-c76a-4bfe-b9d4-a8c803fe5f62\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = dict(zip(tfidf_vectorizer.get_feature_names(), np.sum(tfs, axis=1)))\n",
    "print(words)\n",
    "#print()\n",
    "p = figure(x_range=[k for k,v in words.items()], plot_width=800, plot_height=800, title=None)\n",
    "p.vbar(x=[k for k,v in words.items()], top=[v for k,v in words.items()], width=10)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linearize results into a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapToSpaceSampling(points):\n",
    "    # just take the first n² < #points Points\n",
    "    points = points[: int(np.sqrt(len(points)))**2]\n",
    "    grid = np.dstack(np.meshgrid(np.linspace(np.min(points[:, 0]), np.max(points[:, 0]), int(np.sqrt(len(points)))),\n",
    "                       np.linspace(np.min(points[:, 1]), np.max(points[:, 1]), int(np.sqrt(len(points)))))).reshape(-1, 2)\n",
    "    cost = cdist(points, grid, \"sqeuclidean\").astype(np.float64)\n",
    "    print(cost.shape)\n",
    "    cost *= 100000 / cost.max()\n",
    "    row_ind_lapjv, col_ind_lapjv, _ = lapjv(cost, verbose=True, force_doubles=True)\n",
    "    return grid[row_ind_lapjv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeClusterTopography(points, values, width, height, interpolation='linear'):\n",
    "    # lay grid over the points so that all points are covered\n",
    "    grid_x, grid_y = np.mgrid[np.min(points[:,0]):np.max(points[:,0]):width*1j, np.min(points[:,1]):np.max(points[:,1]):height*1j]\n",
    "    return griddata(points, values[:len(points)], (grid_x, grid_y), method=interpolation, fill_value=np.min(values[:len(points)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scatter(data, width=600, height=600, viz='scatter'):\n",
    "    display(Javascript(\"\"\"\n",
    "        (function(element){\n",
    "            require(['scatter'], function(scatter) {\n",
    "                scatter(element.get(0), %s, %d, %d, %s);\n",
    "            });\n",
    "        })(element);\n",
    "    \"\"\" % (json.dumps(data), width, height, json.dumps(viz))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "outputs": [],
   "source": [
    "def save(payload):\n",
    "    name = \"c\" + str(payload['params']['num_clusters']) +\"-t\" + str(payload['params']['num_topics']) + \"_\" + str(payload['params']['embedding'])\n",
    "    if payload['params']['embedding'] == 'tSNE':\n",
    "        name += \"_p\" + str(payload['params']['perplexity']) + \"-lr\" + str(payload['params']['learning_rate'])\n",
    "    with open('./dumps/' + name + '.json', 'w') as dumpfile:\n",
    "        json.dump(payload, dumpfile, sort_keys=True, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "local_metadata": {},
    "remote_metadata": {
     "tags": [
      "remove_cell"
     ]
    }
   },
   "outputs": [],
   "source": [
    "def visualize(targetDim=2,tfs=None,dimreduction='LSA', clustering='KMEANS', embedding='LDA', num_topics=20, num_clusters=3, perplexity=5, learning_rate=200, error='cluster_error', interpolation='linear', viz='scatter'):\n",
    "    \n",
    "    # viz dimensions\n",
    "    width = 860\n",
    "    height = 400\n",
    "    \n",
    "    \n",
    "    if dimreduction == 'LSA':\n",
    "        tfs_reduced, model = LSA(tfs, num_topics=num_topics)\n",
    "    elif dimreduction == 'NMF':\n",
    "        tfs_reduced, model = NMF(tfs, num_topics=num_topics)\n",
    "    else:\n",
    "        return 'No dimensionality reduction technique was selected!'\n",
    "    \n",
    "    if clustering == 'KMEANS':\n",
    "        clusters = cluster(tfs_reduced, num_topics=num_clusters)\n",
    "    else:\n",
    "        return 'No clustering technique was selected!'\n",
    "    \n",
    "    if embedding == 'LDA':\n",
    "        tfs_embedded, lda = dimReductionLDA(tfs_reduced, clusters=clusters, targetDim=targetDim)\n",
    "    elif embedding == 'tSNE':\n",
    "        tfs_embedded = dimReductiontSNE(tfs_reduced, perplexity=perplexity, learning_rate=learning_rate, targetDim=targetDim)\n",
    "    else:\n",
    "        return 'No dimensionality reduction technique was selected!'\n",
    "    \n",
    "    # compute linearization\n",
    "    tfs_mapped = mapToSpaceSampling(tfs_embedded) if targetDim == 2 else [0]*len(tfs_embedded)\n",
    "    \n",
    "    # compute top words (TODO: could be flawed)\n",
    "    tfidf_feature_names = [str(token) for token in tfidf_vectorizer.get_feature_names()]\n",
    "    cluster_words = np.array([words for i, words in get_top_words_cluster(model, clusters.cluster_centers_, tfidf_feature_names, 5).items()])\n",
    "    [print(i, words) for i,words in enumerate(cluster_words)]\n",
    "    \n",
    "    #compute cluster topography\n",
    "    similarity_to_cluster_centers = [norm(x-clusters.cluster_centers_[clusters.labels_[i]]) for i,x in enumerate(tfs_reduced)]\n",
    "    #similarity_to_cluster_centers = similarity_to_cluster_centers / norm(similarity_to_cluster_centers)\n",
    "    reduction_error = np.max(lda.decision_function(tfs_reduced), axis=1) if (embedding == 'LDA') else [0]* len(tfs_embedded)\n",
    "    #reduction_error = reduction_error / norm(reduction_error)\n",
    "    mixed = reduction_error + similarity_to_cluster_centers\n",
    "    interpolated_topography = computeClusterTopography(tfs_embedded if viz == 'scatter' else tfs_mapped, similarity_to_cluster_centers if error=='cluster_error' else reduction_error if error=='reduction_error' else mixed, width, height, interpolation)\n",
    "    \n",
    "    \n",
    "    if targetDim == 2:\n",
    "        # configure bokeh plot                   \n",
    "        source = ColumnDataSource(data=dict(\n",
    "            x=tfs_embedded[:, 0],\n",
    "            y=tfs_embedded[:, 1],\n",
    "            x_mapped=tfs_mapped[:, 0],\n",
    "            y_mapped=tfs_mapped[:, 1],\n",
    "            ids=list(cleanProjectTexts().keys()),\n",
    "            #titles=[next((project['title'] for project in loadProjects() if project['id'] == key), ['None']) for key in cleanProjectTexts().keys()],\n",
    "            colours=np.array(d3['Category20'][num_clusters])[clusters.labels_],\n",
    "            labels=clusters.labels_\n",
    "        ))\n",
    "\n",
    "        TOOLTIPS = [\n",
    "            (\"index\", \"$index\"),\n",
    "            (\"id\", \"@ids\"),\n",
    "            #(\"title\", \"@titles\"),\n",
    "        ]\n",
    "        # scatterplot\n",
    "        scatter = figure(plot_width=800, plot_height=800, title=None, toolbar_location=\"below\", tooltips=TOOLTIPS, tools='tap,pan,wheel_zoom')\n",
    "        scatter.scatter('x', 'y', size=10,color='colours', legend='labels', source=source)\n",
    "        url = 'http://gepris.dfg.de/gepris/projekt/@ids'\n",
    "        taptool = scatter.select(type=TapTool)\n",
    "        taptool.callback = OpenURL(url=url)\n",
    "        \n",
    "        # mapped scatterplot\n",
    "        mapped_scatter = figure(plot_width=800, plot_height=800, title=None, toolbar_location=\"below\", tooltips=TOOLTIPS, tools='tap,pan,wheel_zoom')\n",
    "        mapped_scatter.scatter('x_mapped', 'y_mapped', size=50,color='colours', legend='labels', source=source)\n",
    "        url = 'http://gepris.dfg.de/gepris/projekt/@ids'\n",
    "        taptool = mapped_scatter.select(type=TapTool)\n",
    "        taptool.callback = OpenURL(url=url)\n",
    "        #show(row(scatter, mapped_scatter))\n",
    "    else:\n",
    "\n",
    "        source = go.Scatter3d(\n",
    "            x=tfs_embedded[:, 0],\n",
    "            y=tfs_embedded[:, 1],\n",
    "            z=tfs_embedded[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "                color=clusters.labels_,                # set color to an array/list of desired values\n",
    "                colorscale='Viridis',   # choose a colorscale\n",
    "                opacity=0.8\n",
    "            )\n",
    "        )\n",
    "\n",
    "        data = [source]\n",
    "        layout = go.Layout(\n",
    "            margin=dict(\n",
    "                l=0,\n",
    "                r=0,\n",
    "                b=0,\n",
    "                t=0\n",
    "            )\n",
    "        )\n",
    "        fig = go.Figure(data=data, layout=layout)\n",
    "        iplot(fig, filename='3d-scatter-colorscale')\n",
    "    \n",
    "    payload = {\n",
    "        'params': {\n",
    "            'targetDim': targetDim,\n",
    "            'dimreduction': dimreduction,\n",
    "            'clustering': clustering,\n",
    "            'embedding': embedding,\n",
    "            'num_topics': num_topics,\n",
    "            'num_clusters': num_clusters,\n",
    "            'perplexity': perplexity,\n",
    "            'learning_rate': learning_rate\n",
    "        },\n",
    "        'project_data': [{'id':pid,'reducedpoint': reducedpoint, 'embpoint':embpoint, 'mappoint':mappoint, 'cluster':cluster, 'error':error} for pid, reducedpoint, embpoint, mappoint, cluster, error in zip(\n",
    "            list(cleanProjectTexts().keys()),\n",
    "            tfs_reduced.tolist(),\n",
    "            tfs_embedded.tolist(),\n",
    "            tfs_mapped.tolist(),\n",
    "            clusters.labels_.tolist(),\n",
    "            reduction_error\n",
    "            \n",
    "        )],\n",
    "        'cluster_data': {\n",
    "            'cluster_words': [ words for i, words in get_top_words_cluster(model, clusters.cluster_centers_, tfidf_feature_names, 5).items()],\n",
    "            'cluster_colour': d3['Category20'][num_clusters]\n",
    "        },\n",
    "        'cluster_topography': np.flip(interpolated_topography.T, axis=0).flatten().tolist()\n",
    "    }\n",
    "    save(payload)\n",
    "    display(HTML(filename=\"scatter.css.html\"))\n",
    "    display(Javascript(\"require.config({paths: {d3: 'https://d3js.org/d3.v5.min'}});\"))\n",
    "    display(Javascript(filename=\"scatter.js\"))\n",
    "    draw_scatter(payload, width, height, viz)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "local_metadata": {
     "scrolled": false
    },
    "remote_metadata": {
     "scrolled": false,
     "tags": [
      "remove_cell"
     ]
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/.local/share/virtualenvs/topicextraction-6DKtt5qs/lib/python3.6/site-packages/traitlets/traitlets.py:1343: SparseEfficiencyWarning:\n",
      "\n",
      "Comparing sparse matrices using == is inefficient, try using != instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca6294bdad345b88208b97c14e84d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, continuous_update=False, description='targetDim', max=3, min=2), Drop…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def s(x,y):\n",
    "    return IntSlider(min=x,max=y, value=(y-x)//2, continuous_update=False)\n",
    "\n",
    "w = interactive(visualize,targetDim=s(2,3),tfs=fixed(tfs), dimreduction=['LSA', 'NMF'], clustering=['KMEANS'], embedding=['LDA', 'tSNE'], num_topics=s(4,48), num_clusters=s(4,14), perplexity=s(5,50), learning_rate=s(100,1000),error=['red_error', 'cluster_error', 'mixed'], interpolation=['linear', 'cubic'], viz=['scatter', 'linearized'])\n",
    "output = w.children[-1]\n",
    "#output.layout.height = '2000px'\n",
    "display(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#%lprun -f visualize visualize(**w.kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "NLPenv-Lin",
   "language": "python",
   "name": "nlpenv-lin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
